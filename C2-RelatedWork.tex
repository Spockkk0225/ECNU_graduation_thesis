\chapter{相关工作}

\section{基于划分的方法}

核密度估计法的计算过程通常涉及对每一个查询点遍历所有数据点并计算其权重，这一步骤往往非常耗时~\cite{gramacki_nonparametric_2018}，特别是在处理大规模数据集时，逐个计算每个数据点对查询点的影响会导致显著的性能瓶颈。为了解决这一问题，一个常见的做法是对数据点进行聚合，即将位置较为接近的数据点合并成一个聚合集，当某次查询覆盖了聚合集中的所有数据点时，可以整体计算聚合集的对核密度的贡献，从而避免逐个计算带来的时间开销~\cite{liu_immens_2013}。

通过这种方法，不仅可以大幅减少计算量，还能有效提升算法的整体效率。不同的划分算法会产生不同的聚合集，这不仅影响到计算效率的提升，还涉及到维护开销的变化。下面将详细介绍几种常见的划分方式及其特点。

\begin{itemize}[leftmargin=*]
	\item \textbf{K-d树}~\cite{chan_efficient_2020, chan_quad_2020, chan_karl_2019}。 K-d树是维护多维空间中的数据点的最常用的数据结构之一，其主要思想是将用一个超平面将数据点沿着某个维度平均分成两半，并在其他维度依次重复执行这一操作。由于每次操作都会将数据点分成两半，最后构成了树状结构，其中每个节点都代表一个超立方体，维护了其中的数据点的信息（特别地，叶节点仅包含一个数据点）。当计算核密度时，如果查询的带宽范围覆盖了整个超立方体或完全不相交，即可直接返回结果，否则继续递归，在更小的子空间中查询。然而，K-d树仅在低维度（大约10维）下有效。对于更高维度，由于分布的稀疏性，K-d树的效率急剧下降，此时另一个变种算法球树更为合适~\cite{gray_nonparametric_2003}。
	
	\item \textbf{网格化}~\cite{hart_kernel_2014, black_highway_1991}。 不同于K-d树这种动态的划分方式，网格化直接将数据空间划分成等间距的网格，每个数据点会被分配到对应的网格中。在计算核密度时，每个网格会被近似成一个点（一般选为网格中心），即实现了连续的数据点离散化操作。由于近似操作，网格化需要选取合适的网格大小：如果网格过大，近似时的误差也会增大；如果网格过小，则会显著增加计算的时间复杂度，尤其是在高维空间中会呈指数增长。
	
	\item \textbf{快速傅里叶变换}~\cite{silverman_algorithm_1982, gramacki_nonparametric_2018}。 为了进一步解决网格化带来的额外计算开销，可以使用快速傅里叶变换加速核密度的计算。具体来说，核密度的计算公式在离散情况下可以视作网格化矩阵和核方程矩阵的卷积，而快速傅里叶变换可以大大提高矩阵卷积的效率。快速傅里叶变换对于大型核和带宽特别有用。然而，对于高维矩阵和稀疏矩阵，其计算成本可能较高~\cite{fan_fast_1994}。
	
	\item \textbf{聚类}~\cite{auber_interactive_2005, abello_ask-graphview_2006, hinneburg_denclue_2007}。 聚类和网格化类似，都是将一些数据点合并成一个点进行计算，不同的是聚类采用各种聚类算法进行划分，这使得对于稀疏分布更加友好。并且，现有的各种层级结构聚类算法也可用于生成层级结构的聚合集，进一步加速计算。
	
	\item \textbf{分桶}~\cite{liu_immens_2013, gramacki_nonparametric_2018, li_interactive_2014}。 分桶也需要将连续的空间划分成若干桶，但和网格化不同的是，桶的分布是不均匀的，因此可以根据数据的分布动态调整桶的分布。在数据点稀疏或不重要的区域，可以分配较大的桶，而在数据密集且需要更高精度的区域，则采用更小的桶。
\end{itemize}

\section{基于时间的方法}

许多工作还考虑了对时间数据的分析。考虑到时间数据的复杂性，现有的工作可以分成如下几类难度：

\begin{itemize}[leftmargin=*]
	\item \textbf{静态数据分析}~\cite{patuelli2007network, mouratidis2006continuous}。静态数据是固定不变的，因此时间属性可以被视作一个单独的维度，并同样建立相关的索引。大部分支持高维核密度估计法的算法都可以直接扩展到静态数据上。
	
	\item \textbf{可持久化数据分析}~\cite{sasikala2014uncertain, cheng2012spatio}。可持久化数据可以被更新或修改，形成新的记录，但不能修改已有的数据。这种数据往往用于记录操作信息，例如计算机日志信息或存储库修改信息。只有一部分算法经过修改后才可以实现可持久化数据的维护。
	
	\item \textbf{流数据分析}~\cite{koudas2004approximate, figueiras2018real, li2021trace}。流数据是一种特殊的可持久化数据，它只会更新最新的数据信息（而不是在任意位置更新分支）。绝大部分数据都可以视作流数据，因为会有源源不断的新数据产生，并且在时间维度上不会和已有数据相交。流数据的分析是最广泛的，因为它的要求相对较低，且在现实世界中应用广泛。
\end{itemize}

\section{核函数的计算}

	加权聚合是核密度计算优化中的一个重要操作，它可以将多个数据点的核密度合并计算。已有的工作只能实现多项式核函数的核密度聚合计算，而对于像余弦核函数和Gaussian核函数这样的非多项式核函数只能拟合到多项式核函数进行计算~\cite{chan_karl_2019, chan_quad_2020}，目前还没有精确计算的方式。
	
	
\section{分布式计算平台}

如果需要将算法扩展至分布式环境，通常会选择将其移植到特定的计算平台上。这种方法使得用户可以专注于算法本身的实现，而无需担心分布式环境下的各种系统设置问题，例如负载均衡和通讯优化等复杂任务。通过利用这些专门设计的计算平台，用户能够极大地简化开发流程，并加速算法的研发与部署。

在分布式环境中运行算法时，数据分布、任务调度、节点间的通信协调以及故障恢复等部署问题是非常具有挑战性的。这些问题不仅增加了系统的复杂性，还可能引入额外的性能瓶颈。现代的计算平台为了减少这些额外开销所带来的效率降低，一般都内置了强大的调度机制，可以自动管理资源分配，确保各个计算节点之间的负载均衡。此外，这些平台还优化了节点间的通信方式，减少数据传输延迟，提高整体的计算效率。

具体来说，当算法被移植到这些计算平台上时，开发者只需关注核心算法逻辑的实现即可。例如在图计算中，用户只需要定义顶点或边的行为，而平台则负责在后端处理所有的并行化细节，包括如何在多个节点上分配任务、如何优化数据传输，以及如何确保所有节点之间的一致性和同步性。这种高度抽象化的编程模型大大降低了分布式计算的门槛，即使是没有分布式开发背景的用户也能够轻松地将自己的算法并行化，并在大规模数据集上高效运行。

不仅如此，这些计算平台还提供了丰富的接口和工具库，进一步增强了算法的可扩展性和灵活性。无论是用于执行复杂的图分析任务、处理海量的数据流还是进行实时的数据挖掘，这些平台都能提供必要的支持。例如，某些平台专门针对幂律图中的负载均衡问题进行了优化，确保即使数据的分布不平衡，也能保持高效的计算性能。其他一些平台则提供了对固态硬盘的顺序读写优化，以提高I/O操作的速度，这对于需要频繁访问磁盘的计算任务尤为重要。

Bulk Synchronous Parallelism（BSP）模型由 Leslie Valiant 于1990年提出~\cite{valiant1990bridging}，旨在提供一种高效的并行计算框架，特别适用于大规模图数据的处理。BSP模型通过将计算过程划分为多个“超级步骤”（supersteps），每个超级步骤包含三个主要阶段：本地计算、通信和同步，能够有效地执行并行任务。这种方法不仅简化了并行编程的复杂性，还提高了计算效率和资源利用率。

基于BSP模型，Vertex-Centric（以点为中心）模式应运而生，并引入了“Think-Like-a-Vertex”（TLAV，像顶点一样思考）的设计理念~\cite{mccune2015thinking}。在以点为中心的计算模式中，顶点是计算和调度的基本单位。每个顶点都可以进行本地计算并向其他顶点发送消息。用户只需要实现一个基于顶点的计算接口，而平台将在所有顶点上执行用户代码，迭代计算固定次数或直到结果收敛。这一模型进一步简化了大规模图计算的设计与实现，使得开发者可以专注于每个顶点的行为和交互，而不必过多考虑底层的并行处理细节。

以点为中心的计算模式有一些变体，例如单阶段模型（Pregel~\cite{malewicz2010pregel}, Pregel+~\cite{yan2015effective}, Flash~\cite{10184838}, Ligra~\cite{DBLP:conf/ppopp/ShunB13}），Scatter-Gather模型（Signal/Collect~\cite{stutz2010signal}）和Scatter-Combine模型（GRE~\cite{yan2014pregel}）。此外，一些已有的并行计算模型，例如Spark，也可以在VertexRDD上提供类似于Pregel的接口来模拟~\cite{gonzalez2014graphx}。然而，以点为中心的计算模式面临着一些潜在挑战，包括负载不平衡问题，这在幂律图中尤为突出，以及在大规模集群上部署时显著的通信开销问题。

一些平台进一步扩展，对边或顶点组进行计算，从而分别发展出了Edge-Centric（以边为中心）和Block-Centric（以块为中心）的计算模式。PowerGraph~\cite{gonzalez2012powergraph}、X-Stream~\cite{roy2013x}、GraphChi~\cite{kyrola2012graphchi}和Chaos~\cite{roy2015chaos}均支持以边为中心的计算模式，通过对边执行任务来解决幂律图中的负载偏斜问题，并充分利用固态硬盘的顺序读写能力。另一方面，Blogel~\cite{yan2014blogel}和Grape~\cite{fan2017grape}支持以块为中心的计算模式，它们将图分割成多个块，使得属于同一块的顶点函数可以在没有通信的情况下进行交互。然而这两个计算模式也有使用上的局限性，以边为中心的计算模式不支持与非邻居顶点的通信，而以块为中心的计算模式在编程实现上较为复杂。

上述所有计算模型产生的输出大小与图的规模成正比，这使得它们不适合可能产生指数级结果的图挖掘问题~\cite{yan2017big, yan2024systems}。为了解决这一问题，像Arabesque~\cite{teixeira2015arabesque}、Fractal~\cite{dias2019fractal}、AutoMine~\cite{mawhirter2019automine}、Peregrine~\cite{jamshidi2020peregrine}和G-thinker~\cite{yan2020g}这样的平台采用了Subgraph-Centric（以子图为中心）的计算模式。在该计算模式中，基本的计算单元是子图（例如三角形或矩形），而不是顶点、边或块。用户需要定义如何构建候选子图，并为每个子图实现一个计算接口。



